# TRDP
(IPCV) Tutored Reasearch and Development Project - CycleGAN

Image-to-image translation task is an important problem of computer vision where the main purpose is to obtain a correspondence between two image domains. One of the most recent achievements in this field are, so called, Cycle Generative Adversarial Networks that tackle a serious issue of Supervised Learning approaches: the necessity of having paired training data. However, while CycleGANs introduce an appealing concept of utilizing unpaired training data, the mapping between two domains can be challenging and ambiguous, therefore this method may fail to converge to a global optimum. In order to combat this problem, we introduce a novel CycleGANs model. The proposed architecture allows to operate on three domains, as opposed to two  domains in the original architecture. This way, falling in local minima is less probable during the optimization stage and more information can be extracted and used to construct a more accurate representation of the target domain. The proposed model has been trained with unpaired data of three types: RGB-footage of the city, semantic segmentation and depth maps, with RGB-footage and semantic segmentation being the target domains. The obtained results prove that Semantic-to-RGB image transfer demonstrates better performance when the depth maps are incorporated in the training process.

